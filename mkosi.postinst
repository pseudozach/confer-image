#!/bin/bash
# mkosi post-installation script
# Runs inside the image after packages are installed

set -euo pipefail

echo "==> Setting up Confer proxy environment"

# Create mount points for secondary disks
mkdir -p /buildroot/mnt/models /buildroot/mnt/config /buildroot/mnt/proxy

# Install Python packages in two stages:
# 1. vLLM system-wide (has modern dependency versions)
# 2. Attestation SDK in venv (has pinned older versions that conflict with vLLM)

# Set up DNS resolution for the chroot (required for pip to reach pypi.org)
mkdir -p /buildroot/etc
if [ -f /etc/resolv.conf ]; then
    cp /etc/resolv.conf /buildroot/etc/resolv.conf
    echo "Copied /etc/resolv.conf to chroot for DNS resolution"
else
    cat > /buildroot/etc/resolv.conf << 'DNSEOF'
nameserver 8.8.8.8
nameserver 8.8.4.4
DNSEOF
    echo "Created /etc/resolv.conf with Google DNS fallback"
fi

# Ensure /tmp exists in the buildroot for pip
mkdir -p /buildroot/tmp

# Verify pip is available
if ! chroot /buildroot which pip3 >/dev/null 2>&1; then
    echo "ERROR: pip3 not found in image. Ensure python3-pip is in Packages= in mkosi.conf"
    exit 1
fi

# Stage 1: Install vLLM system-wide (skip if already installed with same requirements)
echo "==> Installing vLLM packages system-wide"
if [ -f /buildroot/requirements-vllm.lock ]; then
    VLLM_HASH=$(sha256sum /buildroot/requirements-vllm.lock | cut -d' ' -f1)
    VLLM_HASH_FILE="/buildroot/opt/.requirements-vllm.hash"

    if [ -f "$VLLM_HASH_FILE" ] && [ "$(cat "$VLLM_HASH_FILE")" = "$VLLM_HASH" ]; then
        echo "✓ vLLM already installed with matching requirements, skipping"
    else
        echo "Running pip install for vLLM (this may take a while)..."
        cp /buildroot/requirements-vllm.lock /buildroot/tmp/requirements-vllm.lock
        chroot /buildroot python3 -m pip install \
            --break-system-packages \
            --no-cache-dir \
            -r /tmp/requirements-vllm.lock

        # Verify vllm was installed
        if [ -d /buildroot/usr/local/lib/python3.12/dist-packages/vllm ]; then
            echo "✓ vLLM package installed"
            if [ -d /buildroot/usr/local/lib/python3.12/dist-packages/torch ]; then
                echo "✓ PyTorch package installed"
            else
                echo "ERROR: PyTorch not found after pip install"
                exit 1
            fi
        else
            echo "ERROR: vLLM package directory not found after pip install"
            exit 1
        fi

        # Store hash for future builds
        echo "$VLLM_HASH" > "$VLLM_HASH_FILE"
        rm -f /buildroot/tmp/requirements-vllm.lock
    fi
    rm -f /buildroot/requirements-vllm.lock
else
    echo "ERROR: requirements-vllm.lock not found"
    exit 1
fi

# Stage 2: Install attestation SDK in isolated venv (skip if already installed with same requirements)
# NVIDIA's nv-ppcie-verifier has strict version pins that conflict with vLLM
echo "==> Installing attestation SDK in /opt/venv-attestation"
if [ -f /buildroot/requirements-attestation.lock ]; then
    ATT_HASH=$(sha256sum /buildroot/requirements-attestation.lock | cut -d' ' -f1)
    ATT_HASH_FILE="/buildroot/opt/.requirements-attestation.hash"

    if [ -f "$ATT_HASH_FILE" ] && [ "$(cat "$ATT_HASH_FILE")" = "$ATT_HASH" ]; then
        echo "✓ Attestation SDK already installed with matching requirements, skipping"
    else
        echo "Running pip install for attestation SDK..."
        cp /buildroot/requirements-attestation.lock /buildroot/tmp/requirements-attestation.lock

        # Create venv for attestation
        chroot /buildroot python3 -m venv /opt/venv-attestation

        chroot /buildroot /opt/venv-attestation/bin/pip install \
            --no-cache-dir \
            -r /tmp/requirements-attestation.lock

        # Verify attestation SDK was installed
        if chroot /buildroot /opt/venv-attestation/bin/python -c "import nv_attestation_sdk" 2>/dev/null; then
            echo "✓ nv-attestation-sdk installed in venv"
        else
            echo "✓ nv-attestation-sdk package files installed (import check skipped in build env)"
        fi

        # Store hash for future builds
        echo "$ATT_HASH" > "$ATT_HASH_FILE"
        rm -f /buildroot/tmp/requirements-attestation.lock
    fi
    rm -f /buildroot/requirements-attestation.lock
else
    echo "ERROR: requirements-attestation.lock not found"
    exit 1
fi

# Stage 3: Install docling-serve in isolated venv 
echo "==> Installing docling-serve in /opt/venv-docling"
if [ -f /buildroot/requirements-docling.lock ]; then
    DOCLING_HASH=$(sha256sum /buildroot/requirements-docling.lock | cut -d' ' -f1)
    DOCLING_HASH_FILE="/buildroot/opt/.requirements-docling.hash"

    if [ -f "$DOCLING_HASH_FILE" ] && [ "$(cat "$DOCLING_HASH_FILE")" = "$DOCLING_HASH" ]; then
        echo "✓ Docling already installed with matching requirements, skipping"
    else
        echo "Running pip install for docling-serve..."
        cp /buildroot/requirements-docling.lock /buildroot/tmp/requirements-docling.lock

        # Create venv for docling
        chroot /buildroot python3 -m venv /opt/venv-docling

        chroot /buildroot /opt/venv-docling/bin/pip install \
            --no-cache-dir \
            --extra-index-url https://download.pytorch.org/whl/cu128 \
            -r /tmp/requirements-docling.lock

        # Verify docling-serve was installed
        if [ -f /buildroot/opt/venv-docling/bin/docling-serve ]; then
            echo "✓ docling-serve installed in venv"
        else
            echo "ERROR: docling-serve binary not found after pip install"
            exit 1
        fi

        # See: https://docling-project.github.io/docling/usage/gpu/
        PIPELINE_OPTIONS="/buildroot/opt/venv-docling/lib/python3.12/site-packages/docling/datamodel/pipeline_options.py"
        if [ -f "$PIPELINE_OPTIONS" ]; then
            sed -i 's/] = "onnxruntime"/] = "torch"/' "$PIPELINE_OPTIONS"
            echo "✓ Patched RapidOCR to use torch backend"
        else
            echo "ERROR: Could not find pipeline_options.py to patch RapidOCR backend"
            exit 1
        fi

        # See: https://github.com/docling-project/docling-serve/issues/434
        ACCELERATOR_OPTIONS="/buildroot/opt/venv-docling/lib/python3.12/site-packages/docling/datamodel/accelerator_options.py"
        if [ -f "$ACCELERATOR_OPTIONS" ]; then
            echo "Before AcceleratorOptions patch:"
            grep '] = "auto"\|] = "cuda"' "$ACCELERATOR_OPTIONS" || true

            sed -i 's/] = "auto"/] = "cuda"/' "$ACCELERATOR_OPTIONS"

            echo "After AcceleratorOptions patch:"
            grep '] = "auto"\|] = "cuda"' "$ACCELERATOR_OPTIONS" || true

            if grep -q '] = "cuda"' "$ACCELERATOR_OPTIONS"; then
                echo "✓ Patched AcceleratorOptions to default to CUDA"
                # Remove bytecode cache to ensure patched source is used
                rm -rf /buildroot/opt/venv-docling/lib/python3.12/site-packages/docling/datamodel/__pycache__
            else
                echo "ERROR: AcceleratorOptions patch did not apply correctly"
                exit 1
            fi
        else
            echo "ERROR: Could not find accelerator_options.py to patch device default"
            exit 1
        fi

        # See: https://github.com/huggingface/transformers/issues/23145
        LAYOUT_PREDICTOR="/buildroot/opt/venv-docling/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py"
        if [ -f "$LAYOUT_PREDICTOR" ]; then
            echo "Before LayoutPredictor patch:"
            grep -n 'from_pretrained\|\.to(' "$LAYOUT_PREDICTOR" | head -5

            # Remove device_map parameter and add .to(self._device) after model loading
            # Original: self._model = AutoModelForObjectDetection.from_pretrained(
            #               artifact_path, config=self._model_config, device_map=self._device
            #           )
            # Patched:  self._model = AutoModelForObjectDetection.from_pretrained(
            #               artifact_path, config=self._model_config
            #           ).to(self._device)
            python3 -c "
import re
with open('$LAYOUT_PREDICTOR', 'r') as f:
    content = f.read()
content = content.replace(', device_map=self._device', '')
content = re.sub(r'(config=self._model_config\n\s+)\)', r'\1).to(self._device)', content)
with open('$LAYOUT_PREDICTOR', 'w') as f:
    f.write(content)
"

            echo "After LayoutPredictor patch:"
            grep -n 'from_pretrained\|\.to(' "$LAYOUT_PREDICTOR" | head -5

            if grep -q '\.to(self._device' "$LAYOUT_PREDICTOR" && ! grep -q 'device_map' "$LAYOUT_PREDICTOR"; then
                echo "✓ Patched LayoutPredictor to use .to(device) instead of device_map"
                rm -rf /buildroot/opt/venv-docling/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/__pycache__
            else
                echo "ERROR: LayoutPredictor patch did not apply correctly"
                exit 1
            fi
        else
            echo "ERROR: Could not find layout_predictor.py to patch device_map bug"
            exit 1
        fi

        RAPIDOCR_MODELS="/buildroot/opt/venv-docling/lib/python3.12/site-packages/rapidocr/models"
        mkdir -p "$RAPIDOCR_MODELS"
        echo "Downloading RapidOCR torch models..."

        # Detection model
        curl -fsSL "https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.6.0/torch/PP-OCRv4/det/ch_PP-OCRv4_det_infer.pth" \
            -o "$RAPIDOCR_MODELS/ch_PP-OCRv4_det_infer.pth"
        echo "89622c3f3e76b3ac7d10d9434c1f117a7471dba44723885cc04b49932a740d5b  $RAPIDOCR_MODELS/ch_PP-OCRv4_det_infer.pth" | sha256sum -c -

        # Recognition model
        curl -fsSL "https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.6.0/torch/PP-OCRv4/rec/ch_PP-OCRv4_rec_infer.pth" \
            -o "$RAPIDOCR_MODELS/ch_PP-OCRv4_rec_infer.pth"
        echo "cb4265bb4300a2487e93e82ccfa1924bf9cd1194c1a202ab17a96b4911c27e0b  $RAPIDOCR_MODELS/ch_PP-OCRv4_rec_infer.pth" | sha256sum -c -

        # Classification model
        curl -fsSL "https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.6.0/torch/PP-OCRv4/cls/ch_ptocr_mobile_v2.0_cls_infer.pth" \
            -o "$RAPIDOCR_MODELS/ch_ptocr_mobile_v2.0_cls_infer.pth"
        echo "bfe13860824b3365c0c7f7ccfcddc8ff11645c60051739ff18bc9913f60c98e1  $RAPIDOCR_MODELS/ch_ptocr_mobile_v2.0_cls_infer.pth" | sha256sum -c -

        # Recognition dictionary
        curl -fsSL "https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.6.0/paddle/PP-OCRv4/rec/ch_PP-OCRv4_rec_infer/ppocr_keys_v1.txt" \
            -o "$RAPIDOCR_MODELS/ppocr_keys_v1.txt"

        echo "✓ RapidOCR models downloaded"

        # Store hash for future builds
        echo "$DOCLING_HASH" > "$DOCLING_HASH_FILE"
        rm -f /buildroot/tmp/requirements-docling.lock
    fi
    rm -f /buildroot/requirements-docling.lock
else
    echo "ERROR: requirements-docling.lock not found"
    exit 1
fi

echo "✓ Python packages installed successfully"

# Install Vector static binary (apt package has dependency issues with snapshot repos)
echo "==> Installing Vector log shipper"
VECTOR_VERSION="0.51.1"
VECTOR_URL="https://packages.timber.io/vector/${VECTOR_VERSION}/vector-${VECTOR_VERSION}-x86_64-unknown-linux-gnu.tar.gz"
VECTOR_TARBALL="/buildroot/tmp/vector.tar.gz"

if [ ! -f /buildroot/usr/bin/vector ]; then
    echo "Downloading Vector ${VECTOR_VERSION}..."
    curl -fsSL "${VECTOR_URL}" -o "${VECTOR_TARBALL}"

    echo "Extracting Vector..."
    tar -xzf "${VECTOR_TARBALL}" -C /buildroot/tmp/

    # Install binary
    cp "/buildroot/tmp/vector-x86_64-unknown-linux-gnu/bin/vector" /buildroot/usr/bin/vector
    chmod +x /buildroot/usr/bin/vector

    # Clean up
    rm -rf "${VECTOR_TARBALL}" "/buildroot/tmp/vector-x86_64-unknown-linux-gnu"

    echo "✓ Vector ${VECTOR_VERSION} installed"
else
    echo "✓ Vector already installed, skipping"
fi

# Enable services
chroot /buildroot systemctl enable nvidia-persistenced.service
chroot /buildroot systemctl enable nvidia-fabricmanager.service
chroot /buildroot systemctl enable nvidia-cc-attestation.service
chroot /buildroot systemctl enable confer-vllm.service
chroot /buildroot systemctl enable confer-docling.service
chroot /buildroot systemctl enable confer-boot.service
chroot /buildroot systemctl enable confer-proxy.service
chroot /buildroot systemctl enable vector.service

# Make confer-boot script executable
chmod +x /buildroot/usr/local/bin/confer-boot

# Mask services that don't work with read-only rootfs (dm-verity)
# systemd-logind requires writable /var/lib/systemd which we don't have
chroot /buildroot systemctl mask systemd-logind.service

# Set a fixed machine-id for reproducibility AND working DHCP
# systemd-networkd DHCP client requires machine-id to generate DUID
# Using same UUID as mkosi.conf Seed for consistency
echo "a24031c1fc68453d80fa00ad057a5780" > /buildroot/etc/machine-id

echo "==> Setting up Java cacerts symlink for runtime generation"
# Java cacerts cannot be generated deterministically at build time (timestamps vary)
# Instead, we create a symlink to /run/java-cacerts/cacerts which will be populated at boot
# by java-cacerts-init.service using keytool
# This is safe because:
# 1. The keytool binary is in the measured rootfs
# 2. The CA certificates in /etc/ssl/certs/*.pem are in the measured rootfs
# 3. An attacker cannot inject rogue CAs without modifying the measured image
rm -f /buildroot/etc/ssl/certs/java/cacerts
mkdir -p /buildroot/etc/ssl/certs/java
ln -sf /run/java-cacerts/cacerts /buildroot/etc/ssl/certs/java/cacerts
chroot /buildroot systemctl enable java-cacerts-init.service
echo "✓ Cacerts symlink created -> /run/java-cacerts/cacerts (generated at boot)"

echo "==> Removing DKMS build logs for reproducibility"
# Remove DKMS build logs that contain timestamps and non-deterministic build output
find /buildroot/var/lib/dkms -type d -name log -exec rm -rf {} + 2>/dev/null || true

echo "==> Configuring static DNS (no systemd-resolved)"
# Overwrite resolv.conf with static DNS servers
# This must happen after package installation since systemd installs its own
cat > /buildroot/etc/resolv.conf << 'EOF'
# Static DNS configuration for Confer proxy VM
nameserver 8.8.8.8
nameserver 1.1.1.1
EOF

echo "==> Post-install complete"
